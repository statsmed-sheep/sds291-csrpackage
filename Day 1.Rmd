---
title: "Day 1"
author: "Clara Li"
date: "3/9/2020"
output: pdf_document
---
```{r include=FALSE, warning=FALSE, message=FALSE, error=FALSE}
# Some customization to format the file, bring in the data you need.  Do not alter.

# knitr settings to control how R chunks work and how the pdf is compiled when knit.
require(knitr)
opts_chunk$set(
  tidy=TRUE,                     # display code as typed
  size="small",                   # slightly smaller font for code
  tidy.opts=list(width.cutoff=65), # wrap text and long comments
  fig.width=7, fig.height=5           #figure size
)
#Requiring Stat2Data package for the data
# If you're working locally on your computer, you will need to install some of these packages--see code below.
#install.packages(Stat2Data) 
require(Stat2Data)
require(tidyverse)
require(ipumsr)
require(mosaic)
require(stargazer)
require(skimr)
```

```{r}
# Note that you can pass in the loaded DDI into the `read_ipums_micro()`
usa_ddi <- read_ipums_ddi("usa_00001.xml")
usa_data <- read_ipums_micro(usa_ddi, verbose = FALSE)

#Finding the variables that have a label
usa_data %>%
  select_if(is.labelled)

# Convert the labels to factors (and drop the unused levels)
usa_data2 <- usa_data %>%
  mutate(sex_factor = droplevels(as_factor(SEX)),
         marital_factor=droplevels(as_factor(MARST)),
         newchild_factor=droplevels(as_factor(FERTYR)),
         race_factor= droplevels(as_factor(RACE)),
         hispan_factor= droplevels(as_factor(HISPAN)),
         educ_factor= droplevels(as_factor(EDUC)),
         hinsur_factor= droplevels(as_factor(HCOVANY)),
         degfield_factor= droplevels(as_factor(DEGFIELD)),
         empstat_factor= droplevels(as_factor(EMPSTAT)),
         occ_factor= droplevels(as_factor(OCC)),
         ind_factor= droplevels(as_factor(IND)),
         diffmob_factor=droplevels(as_factor(DIFFMOB)),
         diffcare_factor=droplevels(as_factor(DIFFCARE)),
         vetstat_factor=droplevels(as_factor(VETSTAT)),
         pwstate_factor=droplevels(as_factor(PWSTATE2)),
         tranwork_factor=droplevels(as_factor(TRANWORK))
  )
```

# Exercise 1. Make an indicator variable of whether someone is employed or not from empstat_factor. A reminder of the code from where you’ve done this before:

# Exercise 2. Recode newchild_factor so that it is a binary variable: yes vs. no.

```{r}
newchild_factor<-usa_data2 %>%
  filter(newchild_factor != "N/A") %>% 
  mutate(bchild=if_else(newchild_factor=="Yes",1,0))
```

# Exercise 3.

# Exercise 4. Filter only the observations that are currently employed. Remember the filter function that we’ve seen before.

```{r}
usa_data2new<-usa_data2 %>% 
  filter(empstat_factor == 1)
```

# Exercise 5.

<<<<<<< HEAD
```{r}
usa_data2new<-usa_data2 %>% 
  select("AGE", "RACE", "TRANTIME", "degfield_factor", "empstat_factor", "SEX", "newchild_factor", "pernum", "serial", "diffmob_factor", "stem_factor")
```

# Exercise 6.
=======
# Exercise 6.Use the str() function to have R report the structure of the data to you.
```{r}
str(usa_data2)
```


# Exercise 7.Use favstats and tally functions from the mosaic package to look at each of the variables you have included in your data extract.

```{r}
library(mosaic)
favstats(~AGE, data=usa_data2)
favstats(~UHRSWORK, data=usa_data2)
favstats(~INCTOT, data=usa_data2)
favstats(~FTOTINC, data=usa_data2)

tally(~SEX, data=usa_data2)
tally(~MARST, data=usa_data2)
tally(~FERTYR, data=usa_data2)
tally(~RACE,data=usa_data2)
tally(~HISPAN,data=usa_data2)
tally(~HCOVANY,data=usa_data2)
tally(~EDUC,data=usa_data2)
tally(~DEGFIELD, data=usa_data2 )
tally(~EMPSTAT, data=usa_data2 )
tally(~OCC, data=usa_data2 )
tally(~IND, data=usa_data2 )

```
>>>>>>> 982c8a63795399ae175396503941bbeb73fd068f


# Exercise 8.
```{r}
library(skimr)
skim(usa_data2)
```

# Exercise 9.Evaluate each variable. Are the distributions what you would expect? Are there unusual values?

# Exercise 10.Create and interpret a scatterplot of you main explanatory and response variables: age and travel time. For Unusual Observations, now clarify potential leverage/influence/outliers.
